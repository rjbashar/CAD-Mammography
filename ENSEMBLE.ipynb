{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ENSEMBLE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stiflerGit/CAD-Mammography/blob/master/ENSEMBLE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kpQfurfnq2JB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " # CONSTANTS\n",
        "    \n",
        "MODELS = [\n",
        "    {\n",
        "        'name': 'ScratchCNN', \n",
        "        'version': 'v0.0.01', \n",
        "        'dir':'/content/drive/My Drive/Scratch_CNN/'\n",
        "    },\n",
        "#     {\n",
        "#         'name': 'Pretrained_CNN',\n",
        "#         'version':'v0.0.02',\n",
        "#         'dir': '/content/drive/My Drive/PreTrained_CNN/'\n",
        "#     },\n",
        "    {\n",
        "        'name': 'Pretrained-intermediate', \n",
        "        'version': 'v0.0.01', \n",
        "        'dir':'/content/drive/My Drive/PreTrained_CNN-Intermediate/'\n",
        "    },\n",
        "    {\n",
        "        'name': 'ResnetV2', \n",
        "        'version': 'v0.0.01', \n",
        "        'dir':'/content/drive/My Drive/ResNet/'\n",
        "    },\n",
        "]\n",
        "\n",
        "WORK_DIR = './drive/My Drive/ENSEMBLE/'\n",
        "\n",
        "VERSION = 'v0.0.01'\n",
        "\n",
        "# dataset\n",
        "IMAGE_SIZE=[224,224]\n",
        "DATASET_PATH  = '/content/drive/My Drive/CI_FinalProject/'\n",
        "TRAIN_IMGS_FILE_NAME = 'train_img_%d.npy' % IMAGE_SIZE[0]\n",
        "TRAIN_LABELS_FILE_NAME = 'train_lab.npy'\n",
        "TEST_IMGS_FILE_NAME = 'public_test_image_%d.npy' % IMAGE_SIZE[0]\n",
        "TEST_LABELS_FILE_NAME = 'public_test_label.npy'\n",
        "BATCH_SIZE=64\n",
        "val_split=0.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWlUgJCfs2Qn",
        "colab_type": "code",
        "outputId": "4d3b1702-86cf-40b5-9b28-66c63a27b34e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists(WORK_DIR):\n",
        "    os.makedirs(WORK_DIR)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3r8kDf231wJh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have to preprocess data in the same way we did in the training"
      ]
    },
    {
      "metadata": {
        "id": "eGSecEgN1sBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7f52b940-f8e7-4a09-a9a6-b935b0e6c887"
      },
      "cell_type": "code",
      "source": [
        "# PRE-PROCESS DATASET\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_gray_imgs = np.load(os.path.join(DATASET_PATH, TRAIN_IMGS_FILE_NAME))\n",
        "train_lbls = np.load(os.path.join(DATASET_PATH, TRAIN_LABELS_FILE_NAME))\n",
        "\n",
        "print(train_lbls.shape) # 2864 images (it is a quite small dataset)\n",
        "print(np.count_nonzero(train_lbls)) # 1546 \n",
        "# 1546 images belong to class 1, this means 1318 images belong to class 0\n",
        "# so our class distribution is good\n",
        "\n",
        "# we have to equally distribute otherwise the error:\n",
        "### Training and validation subsets have different number of classes after the \n",
        "### split. If your numpy arrays are sorted by the label, you might want to shuffle them.\n",
        "# could be raised. This is due to the distribution of classes of the labels.\n",
        "# for example after the split, the training labels set contains both class 1 and 2,\n",
        "# and on the other hand validation labels set contains either class 1 or class 2.\n",
        "# Even if the train data would cointain both the classes it's better to equally \n",
        "# distribute the two classes over the sets.\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_gray_imgs, train_lbls,\n",
        "                                                  test_size=val_split, \n",
        "                                                  stratify=train_lbls)\n",
        "\n",
        "del(X_train, y_train)\n",
        "valid_samples = len(X_val)\n",
        "\n",
        "X_val = 1./32768 * X_val\n",
        "X_val = X_val - 1.\n",
        "# this is done to transform the gray imgs into rgb images\n",
        "X_val = np.stack((X_val,)*3, axis=-1)\n",
        "\n",
        "del(train_gray_imgs)\n",
        "del(train_lbls)\n",
        "\n",
        "test_gray_imgs = np.load(os.path.join(DATASET_PATH, TEST_IMGS_FILE_NAME))\n",
        "test_gray_imgs = 1./32768 * test_gray_imgs\n",
        "test_gray_imgs = test_gray_imgs - 1.\n",
        "test_rgb_imgs = np.stack((test_gray_imgs,)*3, axis=-1)\n",
        "test_lbls = np.load(os.path.join(DATASET_PATH, TEST_LABELS_FILE_NAME))\n",
        "\n",
        "del(test_gray_imgs)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2864,)\n",
            "1546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0JCj1rH-2Bhe",
        "colab_type": "code",
        "outputId": "963e67cd-fbde-4948-ed5d-8b7099382da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# PRE-PROCESS DATASET \n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "validation_iterator = test_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_iterator = test_datagen.flow(test_rgb_imgs, test_lbls, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kMOC0SjRRT7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import h5py\n",
        "from keras import models\n",
        "\n",
        "# https://github.com/keras-team/keras/issues/11683\n",
        "\n",
        "def fix_layer0(filename, batch_input_shape, dtype):\n",
        "    with h5py.File(filename, 'r+') as f:\n",
        "        model_config = json.loads(f.attrs['model_config'].decode('utf-8'))\n",
        "        layer0 = model_config['config']['layers'][0]['config']\n",
        "        layer0['batch_input_shape'] = batch_input_shape\n",
        "        layer0['dtype'] = dtype\n",
        "        f.attrs['model_config'] = json.dumps(model_config).encode('utf-8')\n",
        "        \n",
        "def open_model(model_path, input_shape):\n",
        "    while True:\n",
        "        try:\n",
        "            m = models.load_model(model_path)\n",
        "            return m\n",
        "        except:\n",
        "            fix_layer0(model_path, input_shape, 'float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vn-m39tW2HiR",
        "colab_type": "code",
        "outputId": "03c89ae5-92f8-4afe-ea32-79c962fed5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "from keras import models as models\n",
        "\n",
        "input_shape = [None, IMAGE_SIZE[0], IMAGE_SIZE[1], 3]\n",
        "\n",
        "mymodels = []\n",
        "\n",
        "for i,m in enumerate(MODELS):\n",
        "    model_path = os.path.join(m['dir'], m['version'], 'model') + '.h5'\n",
        "    print('loading model at path %s'%model_path)\n",
        "    mymodels.append(open_model(model_path, input_shape))\n",
        "    print('model loaded')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading model at path /content/drive/My Drive/Scratch_CNN/v0.0.01/model.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "model loaded\n",
            "loading model at path /content/drive/My Drive/PreTrained_CNN-Intermediate/v0.0.01/model.h5\n",
            "model loaded\n",
            "loading model at path /content/drive/My Drive/ResNet/v0.0.01/model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aQRGZaaxlhjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Average\n",
        "\n",
        "input_tensor = Input(shape=(224,224,3), name='input_tensor', dtype='float32')\n",
        "\n",
        "output_tensors = []\n",
        "for m in mymodels:\n",
        "    output_tensor = m(input_tensor)\n",
        "    output_tensors.append(output_tensor)\n",
        "    \n",
        "output_tensor = Average()(output_tensors)\n",
        "ensemble_model = models.Model(input_tensor, output_tensor, name='ensemble')\n",
        "\n",
        "ensemble_model.summary()\n",
        "\n",
        "predicts = ensemble_model.predict(X_val) \n",
        "predicts = predicts.argmax(axis=-1)\n",
        "print(predicts)\n",
        "\n",
        "# def ensemble(models, model_input):\n",
        "    \n",
        "#     outputs = [model.outputs[0] for model in models]\n",
        "#     y = Average()(outputs)\n",
        "    \n",
        "#     model = Model(model_input, y, name='ensemble')\n",
        "    \n",
        "#     return model\n",
        "\n",
        "# input_tensor = Input(shape=(224,224,3), name='input_tensor', dtype='float32')\n",
        "# ensemble_model = ensemble(mymodels,input_tensor)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52a7Aa7DzNNN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "\n",
        "def evaluate(predicted, labels):\n",
        "    correct = 0\n",
        "    for i in range(len(labels)):\n",
        "        if predicted[i] == labels[i]:\n",
        "            correct = correct+1\n",
        "    return correct / len(labels)\n",
        "\n",
        "for i,m in enumerate(mymodels):\n",
        "    categorical_predicts = m.predict(X_val)\n",
        "    predicts = np.argmax(categorical_predicts, axis=-1)\n",
        "    print('model_{} evaluate: {}'.format(MODELS[i][\"name\"],\n",
        "                                        evaluate(predicts, y_val)))\n",
        "categorical_predicts = ensemble_model.predict(X_val)\n",
        "predicts = np.argmax(categorical_predicts, axis=-1)\n",
        "print('ensemble evaluate: {}'.format(evaluate(predicts, y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xtyei2Lj0ECw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for i,m in enumerate(mymodels):\n",
        "#     m.evaluate(X,y)\n",
        "    \n",
        "# ensemble_model.evaluate(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}